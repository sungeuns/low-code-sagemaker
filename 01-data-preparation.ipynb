{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9efd29-04e7-40d7-a7e7-33a816d7ed46",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "Image classification을 위한 데이터셋 예시 (Wonders of the World Image Dataset)\n",
    "- Kaggle : https://www.kaggle.com/datasets/balabaskar/wonders-of-the-world-image-classification?resource=download\n",
    "\n",
    "해당 이미지 데이터는 kaggle 계정으로 로그인 후 다운로드 받을 수 있습니다.\n",
    "\n",
    "### 이미지 데이터 준비\n",
    "\n",
    "기존의 구조\n",
    "\n",
    "```\n",
    "image-dir\n",
    "  - class1\n",
    "    - img1.jpg\n",
    "    - img2.jpg\n",
    "      ...\n",
    "  - class2\n",
    "    - img1.jpg\n",
    "    - img2.jpg\n",
    "    \n",
    "...\n",
    "```\n",
    "\n",
    "이것을 train/test 데이터를 10% 비율 정도로 나누어서 s3에 올려놓도록 합니다.\n",
    "만일 이미 train/test가 나뉜 데이터를 받았다면, 아래에 dataset split 하는 부분은 진행하지 않고 s3에 업로드만 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21260df0-7e95-44c3-b966-04c5c7e0546b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9ce3e-d5eb-42a0-9f0e-af9c73866236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def copy_data(src_path, dst_path):\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copyfile(src_path, dst_path)\n",
    "\n",
    "def split_image_dataset(image_data_dir, output_dir):\n",
    "    label_list = os.listdir(image_data_dir)\n",
    "    \n",
    "    for label in label_list:\n",
    "        label_dir = os.path.join(image_data_dir, label)\n",
    "        image_list = os.listdir(label_dir)\n",
    "        \n",
    "        random.shuffle(image_list)\n",
    "        ratio = int(len(image_list) / 10)\n",
    "        train_data = image_list[ratio:]\n",
    "        test_data = image_list[:ratio]\n",
    "        assert len(image_list) == len(train_data) + len(test_data)\n",
    "        assert len(train_data) > len(test_data)\n",
    "        \n",
    "        for train_image in train_data:\n",
    "            current_path = os.path.join(image_data_dir, label, train_image)\n",
    "            copy_path = os.path.join(output_dir, \"train\", label, train_image)\n",
    "            copy_data(current_path, copy_path)\n",
    "        \n",
    "        for test_image in test_data:\n",
    "            current_path = os.path.join(image_data_dir, label, test_image)\n",
    "            copy_path = os.path.join(output_dir, \"test\", label, test_image)\n",
    "            copy_data(current_path, copy_path)\n",
    "            \n",
    "        print(f\"Label [{label}] => train: {len(train_data)}, test: {len(test_data)}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dec092-ee66-4889-b58c-f526b3546802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_image_dataset(\"data/wwi\", \"data/wwi-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb9c13-bdde-4301-9a2a-f2f0ccaacdc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### S3에 데이터 업로드\n",
    "\n",
    "- SageMaker를 활용할 때 S3는 가장 기본이 되는 스토리지입니다.\n",
    "- 이미 train/test 나뉜 데이터셋이 준비되었다면 아래와 같이 default bucket에 업로드를 진행합니다.\n",
    "- jupyter shell에서 실행해도 되지만 terminal 에서 그냥 실행해도 상관 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f184d5ad-9f3c-4706-9f92-574d46ae535c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir data; cd data; wget [데이터 경로]; tar zxvf wwi-dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c5192-a23e-416d-8966-396b782fc2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52078fbb-1c21-4d68-974c-ce6b07fbd8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !aws s3 cp data/wwi-dataset s3://{bucket}/lowcode-sm/wwi-dataset/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c9f35-9121-4543-b5b3-78a343e5543c",
   "metadata": {},
   "source": [
    "이제 이미지 데이터셋이 준비되었기 때문에 활용이 가능합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021f286-8ca1-499f-9663-a18160abb434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3938f94-e197-47c8-85f2-2473711eb3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae0d254e-7391-47eb-abd7-37f1c6887580",
   "metadata": {},
   "source": [
    "## Time series 데이터 준비\n",
    "\n",
    "- 아래 데이터의 경우 time-series 테스트를 위해서 필요한 내용입니다.\n",
    "- 따라서, time-series 실습을 진행하지 않는 경우 아래 내용을 진행 할 필요가 없습니다.\n",
    "\n",
    "Time series를 위한 데이터셋\n",
    "- UCI electricty 경로 : `s3://sagemaker-sample-files/datasets/timeseries/uci_electricity/LD2011_2014.txt.zip`\n",
    "\n",
    "데이터가 없다면 위의 경로에서 데이터를 받은 후 압축을 풀고 아래의 과정을 진행하면 됩니다.\n",
    "만일 이미 train/test 가 나뉘어 데이터가 준비되어 있다면, 해당 데이터를 받아서 s3에 올려놓으면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb5bc9-3398-4eb6-bf82-3af183fa1f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd data; aws s3 cp s3://sagemaker-sample-files/datasets/timeseries/uci_electricity/LD2011_2014.txt.zip . ; mkdir uci-elec; unzip LD2011_2014.txt.zip -d uci-elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0607ef-3768-4c7f-a3eb-bf32760379e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661602d-3f48-49b4-a741-122a736ad6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"data/uci-elec/LD2011_2014.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b175c1-463b-4818-826c-8027dc06a11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_path, sep=\";\", index_col=0, parse_dates=True, decimal=\",\")\n",
    "num_timeseries = df.shape[1]\n",
    "data_kw = df.resample(\"2H\").sum() / 8\n",
    "timeseries = []\n",
    "for i in range(num_timeseries):\n",
    "    timeseries.append(np.trim_zeros(data_kw.iloc[:, i], trim=\"f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84eed3-fe46-45dc-8378-cf188dbb02f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e049b38-f1a2-4c6b-8f68-7d85ccef1805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(20, 20), sharex=True)\n",
    "axx = axs.ravel()\n",
    "for i in range(0, 10):\n",
    "    timeseries[i].loc[\"2014-01-01\":\"2014-01-14\"].plot(ax=axx[i])\n",
    "    axx[i].set_xlabel(\"date\")\n",
    "    axx[i].set_ylabel(\"kW consumption\")\n",
    "    axx[i].grid(which=\"minor\", axis=\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6021019-ef1e-4768-a24d-17e6c83801b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we use 2 hour frequency for the time series\n",
    "freq = \"2H\"\n",
    "\n",
    "# we predict for 7 days\n",
    "prediction_length = 7 * 12\n",
    "\n",
    "# we also use 7 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 7 * 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ea7e9-3b83-4e53-8d83-7888de7a26ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_dataset = pd.Timestamp(\"2014-01-01 00:00:00\", freq=freq)\n",
    "end_training = pd.Timestamp(\"2014-09-01 00:00:00\", freq=freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06737448-bc3e-48e0-94ea-04cb8a489bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[\n",
    "            start_dataset : end_training - timedelta(days=1)\n",
    "        ].tolist(),  # We use -1, because pandas indexing includes the upper bound\n",
    "    }\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754079af-3350-4a23-961a-c240ceaa4d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_test_windows = 4\n",
    "\n",
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset : end_training + timedelta(days=k * prediction_length)].tolist(),\n",
    "    }\n",
    "    for k in range(1, num_test_windows + 1)\n",
    "    for ts in timeseries\n",
    "]\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac59e0-0108-4be2-ac55-6e40deba3759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, \"wb\") as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3682a10c-5d03-4040-9360-c2e34dccc196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = \"data/uci-elec-dataset\"\n",
    "os.makedirs(os.path.join(output_dir, \"train\"))\n",
    "os.makedirs(os.path.join(output_dir, \"test\"))\n",
    "train_path = os.path.join(output_dir, \"train\", \"train.json\")\n",
    "test_path = os.path.join(output_dir, \"test\", \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0e6b3-f889-4f9a-86d8-edf2d4130a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "write_dicts_to_file(train_path, training_data)\n",
    "write_dicts_to_file(test_path, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c704e-055b-43d8-92e4-6db6be217e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fed66ac4-c40c-4348-8ce4-84c666b6655c",
   "metadata": {},
   "source": [
    "### 시계열 데이터 S3에 업로드\n",
    "\n",
    "- 이미 준비된 데이터가 있다면 s3에 올려놓도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd254083-e9a7-4969-8032-a4866f21568e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir -p data; cd data; wget [데이터 주소]; tar zxvf uci-elec-dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53cf64-9be8-420e-8502-2315c398a9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !aws s3 cp data/uci-elec-dataset s3://{bucket}/lowcode-sm/uci-elec-dataset/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399f107-8bdc-4fdb-84f8-3659d7408847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d18c9354-2bc3-42eb-a59b-b2ed57d4ec5d",
   "metadata": {},
   "source": [
    "## Tabular 데이터 S3에 업로드\n",
    "\n",
    "Kaggle 의 housing price를 예측하는 regression 용 데이터입니다.\n",
    "- https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153257f-8bca-4adb-acdc-c44d1886b337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir -p data; cd data; mkdir -p hp; wget [데이터 주소]; unzip house-prices-advanced-regression-techniques.zip -d hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902dc891-86ca-4842-aedd-dff2ad879561",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !aws s3 cp data/hp s3://{bucket}/lowcode-sm/hp/ --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4412f-02a6-41e3-a209-923575be960e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
